main.logdir = 'logs'
logging.mute = ['matplotlib', 'PIL']

planet.num_runs = 1
planet.ping_every = 0
planet.resume_runs = False
planet.config = 'default'

planet.params.tasks = ['habitat']
planet.params.isolate_envs = 'none'  # Don't change
planet.params.action_repeat = 1
planet.params.num_seed_episodes = 5
planet.params.train_steps = 5e3
planet.params.test_steps = 50
planet.params.max_steps = 5e7  # Maximum number of training steps
planet.params.max_task_length = 500  # Maximum sequence length
planet.params.divergence_scale = 1.0

planet.tf.options.log_device_placement = False
# planet.tf.options.device_count = {'GPU': 0, 'CPU': 4}
planet.tf.options.inter_op_parallelism_threads = 1  # Don't change

planet.tf.gpu_options.allow_growth = True
planet.tf.gpu_options.visible_device_list = '1'
# planet.tf.gpu_options.per_process_gpu_memory_fraction = 0.5

planet.tf.debugger = False

DiscreteWrapper.sample = False
Habitat.task = 'pointnav'
Habitat.dataset = 'habitat_test'
Habitat.gpu_id = 0
Habitat.image_key = 'rgb'
Habitat.slack_reward = -0.01
Habitat.success_reward = 10.0
